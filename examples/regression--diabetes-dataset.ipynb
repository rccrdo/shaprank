{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `shaprank` - An application to a _regression_ problem\n",
    "In this notebook we run through a feature ranking example based on the `scikit-learn`'s dataset `diabetes`. We rely on `catboost` to grow a simple tree-based model that consumes all raw input features and then use this model trained on default hyper-parameters to produce the (Tree)SHAP values consumed by `shaprank`.\n",
    "\n",
    "For the sake of compactness, to drive the main points, we only work with the full dataset and take no splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required modules:\n",
    "- `shaprank`: ranking engine\n",
    "- `shaprank.explain`: an optional module with utilities to generate (Tree)SHAP-values given a model and the input data\n",
    "- `examples`: the helper module supporting this tutorial notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "import shaprank\n",
    "import shaprank.addons.explain\n",
    "\n",
    "import examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `diabetes` dataset (part of `scikit-learn`) into the frame `df`. The variables `c_inputs` and `c_output` are, respectively, the list of input features' names and the name of the regression target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, c_inputs, c_output = examples.load_dataset_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a `catboost` model on the raw data and using default hyper-parameters and then generate per-example (Tree)SHAP-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model = examples.fit_catboost_regressor(df, c_inputs, c_output)\n",
    "\n",
    "# concatenate the target column to the frame of SHAP values using `c_keep`\n",
    "logging.info(\"Evaluating the SHAP values; find a few examples below.\")\n",
    "df_shap = shaprank.addons.explain.catboost.eval_shap_values(\n",
    "    cb_model, df, c_keep=[c_output], prefix=\"\"\n",
    ")\n",
    "df_shap.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy-search based feature ranking\n",
    "\n",
    "Rank the input features using a \"greedy search\" algorithm that iteratively selects those features that provide the least contribution to a given optimization objective. Below, we inspect the results for `rmse` and `mae`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = shaprank.rank_regressor_features(\n",
    "    df_shap, c_inputs, c_output, eval_metric=\"mae\", verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = shaprank.rank_regressor_features(\n",
    "    df_shap, c_inputs, c_output, eval_metric=\"rmse\", verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `l1` ranking below coincides with the \"average absolute SHAP value\" ranking produced by `shap`'s [Global Bar Plot](https://shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/bar.html#Global-bar-plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_shap[c_inputs] - df_shap[c_inputs].mean(axis=0)).abs().mean(axis=0).sort_values(\n",
    "    ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Note that the `rmse` metric favours input `bmi` over `s5` whereas the `mae` metric and `shap`'s bar plot would rather pick `s5` over `bmi`. \n",
    "\n",
    "Which of these two inputs supports the better approximation of the target? Albeit marginally, `bmi` should be preferred over `s5` when the loss takes on a MSE-like form, resulting in a training loss on average `2%` smaller than the alternative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model_bmi = examples.fit_catboost_regressor(df, [\"bmi\"], c_output)\n",
    "cb_model_s5 = examples.fit_catboost_regressor(df, [\"s5\"], c_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('shap-rank')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b819bc46c6b74a1d331d6e9b49c023dff365764da9b4d89c6328cd6eecce2d2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

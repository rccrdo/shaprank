{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `shaprank` - An application to a _classification_ problem\n",
    "In this notebook we run through a feature ranking example based on the `scikit-learn`'s dataset `breast cancer`. We rely on `catboost` to grow a simple tree-based model that consumes all raw input features and then use this model trained on default hyper-parameters to produce the (Tree)SHAP values consumed by `shaprank`.\n",
    "\n",
    "For the sake of compactness, to drive the main points, we work only with the full dataset and take no splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "import shaprank\n",
    "import shaprank.addons.explain\n",
    "\n",
    "import examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `breast cancer` dataset - part of `scikit-learn`, - into the frame `df`. The variables `c_inputs` and `c_output` are, respectively, the list of input features' names and the name of the binary classification target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, c_inputs, c_target = examples.load_dataset_breast_cancer()\n",
    "c_output = \"label\"\n",
    "df[c_output] = df[c_target] == \"malignant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model = examples.fit_catboost_classifier(df, c_inputs, c_output)\n",
    "\n",
    "# concatenate the target column to the frame of SHAP values using `c_keep`\n",
    "logging.info(\"Evaluating the SHAP values; find a few examples below.\")\n",
    "df_shap = shaprank.addons.explain.catboost.eval_shap_values(\n",
    "    cb_model, df, c_keep=[c_output], prefix=\"\"\n",
    ")\n",
    "df_shap.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy-search based feature ranking\n",
    "\n",
    "Rank the input features using a \"greedy search\" algorithm that iteratively selects those features that provide the least contribution in terms of a given optimization objective. We inspect the results for `recall`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_positives = df[c_output].mean()\n",
    "\n",
    "\n",
    "result = shaprank.rank_classifier_features(\n",
    "    df_shap,\n",
    "    c_inputs,\n",
    "    c_output,\n",
    "    calib_metric=\"alert_rate\",\n",
    "    calib_metric_target=r_positives,\n",
    "    eval_metric=\"recall\",\n",
    "    calib_metric_penalty=1,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the `shaprank` summary above, the model would be able nearly recall all examples at the target alert-rate used for calibration by consuming just 6 of the 30 features.\n",
    "\n",
    "For the sake of comparison we then train models using the 6 top features selected by `shaprank` and the 6 top-raking features according to the \"average absolute SHAP value\" ranking produced by `shap`'s [Global Bar Plot](https://shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/bar.html#Global-bar-plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_shap[c_inputs]).abs().mean(axis=0).sort_values(ascending=False)[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model_featsel_shaprank = examples.fit_catboost_classifier(\n",
    "    df,\n",
    "    [\n",
    "        \"worst area\",\n",
    "        \"mean concave points\",\n",
    "        \"worst texture\",\n",
    "        \"worst symmetry\",\n",
    "        \"perimeter error\",\n",
    "        \"worst fractal dimension\",\n",
    "    ],\n",
    "    c_output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model_featsel_shap = examples.fit_catboost_classifier(\n",
    "    df,\n",
    "    [\n",
    "        \"worst concave points\",\n",
    "        \"mean concave points\",\n",
    "        \"worst area\",\n",
    "        \"worst radius\",\n",
    "        \"worst perimeter\",\n",
    "        \"worst concavity\",\n",
    "    ],\n",
    "    c_output,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this examples, the model trained on the reduced set of features ranked by `shaprank` achieves on average a loss `50%` smaller than with the alternative feature selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('shap-rank')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b819bc46c6b74a1d331d6e9b49c023dff365764da9b4d89c6328cd6eecce2d2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
